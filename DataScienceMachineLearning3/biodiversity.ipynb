{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChenZijiSubset/coding_class/blob/main/biodiversity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd400fe3",
      "metadata": {
        "id": "dd400fe3"
      },
      "source": [
        "# Golden Plains Roadside Biodiversity"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa94d64b",
      "metadata": {
        "id": "fa94d64b"
      },
      "source": [
        "Golden Plains Shire (Australia) is responsible for managing 1834 kilometres of road reserves. Road reserves are not only used for transport but also act as service corridors, in fire prevention, recreation, and occasionally agricultural pursuits. Native vegetation on roadsides is important flora and fauna habitat and landscape character.\n",
        "\n",
        "In 2014, Golden Plains Shire acquired funding through the Victorian Adaptation and Sustainability Partnership (VASP) to undertake Councils ‚ÄòBuilding Adaptive Capacity on Roadsides‚Äô project. The Project was designed to identify significant environmental assets on roadsides, improve roadside management practices and reduce Council‚Äôs risk of potential breaches against Federal and State environmental legislation.\n",
        "\n",
        "The council made this <a href='https://data.gov.au/data/dataset/golden-plains-roadside-biodiversity'>dataset available here</a>.<br>\n",
        "![plain](https://upload.wikimedia.org/wikipedia/commons/thumb/6/6b/Mount_Conner%2C_August_2003.jpg/375px-Mount_Conner%2C_August_2003.jpg)\n",
        "<br>\n",
        "\n",
        "üéØ Today, we will work with a simplified version of this real dataset. The dataset contains a number of biodiversity observations as well as a biodiversity score (`RCACScore`). This exercise consists of the data preparation and feature selection techniques you have learnt: our goal is to predict via linear regression the `RCACScore` using the minimum number of features necessary to maintain a high score.\n",
        "\n",
        "‚ö†Ô∏è This is a long exercises, and it will require you to use many pandas and numpy skills, as well as to plot histograms and line plot with matplotlib. In particular, several questions can best be answered by transforming dataframe series into numpy through some transformers, but then re-transforming the results into a pandas dataframe so you can use the convenience of pandas methods (sorting, for instance). There are several ways to get to the same end result but think of the easiest and most efficient way. If you get stuck, ask a TA!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "115530f5",
      "metadata": {
        "id": "115530f5"
      },
      "source": [
        "üëá Load the data into this notebook as a pandas dataframe named `df`, and display its first 5 rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "c3b0eced",
      "metadata": {
        "id": "c3b0eced"
      },
      "outputs": [],
      "source": [
        "# ADD YOUR CODE HERE -- You can create new markdown and code cells"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e192da16",
      "metadata": {
        "id": "e192da16"
      },
      "source": [
        "Spend a bit of time exploring the dataset, for instance looking at the different columns it contains, it's data types, any missing values. You could use the `describe()` function as a starting point to have an idea of what is going on. Then proceed with the exercise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "2e7976c8",
      "metadata": {
        "id": "2e7976c8"
      },
      "outputs": [],
      "source": [
        "# ADD YOUR CODE HERE -- You can create new markdown and code cells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "042d9b02",
      "metadata": {
        "id": "042d9b02"
      },
      "outputs": [],
      "source": [
        "# ADD YOUR CODE HERE -- You can create new markdown and code cells"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b661f4b",
      "metadata": {
        "id": "7b661f4b"
      },
      "source": [
        "# Duplicates"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48dad803",
      "metadata": {
        "id": "48dad803"
      },
      "source": [
        "üëá Expore the dataframe for duplicates. Remove the duplicates from the dataset if there are any. Overwite the dataframe `df`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "8bd23ecb",
      "metadata": {
        "id": "8bd23ecb"
      },
      "outputs": [],
      "source": [
        "# ADD YOUR CODE HERE -- You can create new markdown and code cells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "2099df30",
      "metadata": {
        "id": "2099df30"
      },
      "outputs": [],
      "source": [
        "# Drop them in place and check"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c1d60dd",
      "metadata": {
        "id": "3c1d60dd"
      },
      "source": [
        "# Create label feature\n",
        "üëá We will use the `RCACScore` as our target variable as we want to predict how much this score is. Therefore, save `RCACScore` as the target variable `y` and remove this columns from `df`. We remove the score now, because our next steps are 1. to manipulate our dataframe to replace missing values and 2. scale the variable. We do not ahve missing `y` values, and we do not generally speaking need/want to scale a numerical target variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "7799f5b9",
      "metadata": {
        "id": "7799f5b9"
      },
      "outputs": [],
      "source": [
        "# ADD YOUR CODE HERE -- You can create new markdown and code cells"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "289fafa2",
      "metadata": {
        "id": "289fafa2"
      },
      "source": [
        "# Missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6bb52ea",
      "metadata": {
        "id": "c6bb52ea"
      },
      "source": [
        "üëá Locate missing values, investigate them, and apply the solutions below accordingly:\n",
        "\n",
        "- Impute with most frequent\n",
        "- Impute with median\n",
        "- Impute a different value which makes sense for the particular data\n",
        "\n",
        "Make changes effective in the dataset `df`. Hints are provided to guide you along in your decision, but before using the hint, try to come up with your own strategy by plotting a historgram of distribution of your variables, or looking a a `value_counts()` output. Trying on your own before looking at the hint is important to your learning."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ce9b323",
      "metadata": {
        "id": "0ce9b323"
      },
      "source": [
        "## `Features with >30% missing data`\n",
        "\n",
        "Identify all features where the amount of missing data is >30% and deal with it approrpiately."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "388a8a83",
      "metadata": {
        "id": "388a8a83"
      },
      "source": [
        "<details>\n",
        "    <summary> üí° Hint </summary>\n",
        "    <br>\n",
        "    ‚ÑπÔ∏è The easiest way to do this is to first create a series containing the percentage of missing values, then filter this for values > 30%, and obtain from it the column names of features (here, the index values) that need to be dropped from the data. Rember that 'isnull().sum()' returns a series of the number of missing value, with the original dataframe column names used as index values.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "54f69cd9",
      "metadata": {
        "id": "54f69cd9"
      },
      "outputs": [],
      "source": [
        "# ADD YOUR CODE HERE -- You can create new markdown and code cells"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e468627b",
      "metadata": {
        "id": "e468627b"
      },
      "source": [
        "## `RoadWidthM`, `PowerlineD` and `Trees`\n",
        "üõÇ Check for missing values in `RoadWidthM`, `PowerlineD` and `Trees` and deal with them appropriately."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24ca71ad",
      "metadata": {
        "id": "24ca71ad"
      },
      "source": [
        "<details>\n",
        "    <summary> üí° Hint </summary>\n",
        "    <br>\n",
        "    ‚ÑπÔ∏è Look at the datatype of <code>PowerlineD</code> and the distribution of the data using the <code>.unique()</code> method. Although <code>PowerlineD</code> is a numeric value, it clearly only has discrete distribution: what would be a logical value to impute? The same applies to <code>Trees</code> and <code>RoadWidthM</code> but for a different reason: they are a continuous variable but there is clearly one value that dominates the distribution: it makes sense to assume that the `nan` represent this most frequent value. So you can impute both of these variables at the same time.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "97846197",
      "metadata": {
        "id": "97846197"
      },
      "outputs": [],
      "source": [
        "# ADD YOUR CODE HERE -- You can create new markdown and code cells"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80588aaa",
      "metadata": {
        "id": "80588aaa"
      },
      "source": [
        "## `Locality` and `EVCNotes`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54aba06e",
      "metadata": {
        "id": "54aba06e"
      },
      "source": [
        "üõÇ Check for missing values in `Locality` and `EVCNotes` for missing values and deal with them appropriately."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7bfcbe0",
      "metadata": {
        "id": "a7bfcbe0"
      },
      "source": [
        "<details>\n",
        "    <summary>üí° Hint </summary>\n",
        "    <br>\n",
        "    ‚ÑπÔ∏è Clearly <code>Locality</code> refers to the name of the county or region where the data comes from. We could impute the most frequent locality, but this would induce some errors. In this case, the best strategy is simply to replace the <code>nan</code> by something meaningful such as 'not known'. <code>EVCNotes</code> is somewhat similar: the <code>nan</code> values indicate that no notes exist, so we should replace them by 'no notes'.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "7bc37f66",
      "metadata": {
        "id": "7bc37f66"
      },
      "outputs": [],
      "source": [
        "# ADD YOUR CODE HERE -- You can create new markdown and code cells"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1c158fe",
      "metadata": {
        "id": "c1c158fe"
      },
      "source": [
        "## `SoilType` and `LandFormLS`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e2bae7c",
      "metadata": {
        "id": "4e2bae7c"
      },
      "source": [
        "üõÇ Check for missing values in `SoilType` and `LandFormLS` and deal with them appropriately."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa559e1f",
      "metadata": {
        "id": "aa559e1f"
      },
      "source": [
        "<details>\n",
        "    <summary>üí° Hint </summary>\n",
        "    <br>\n",
        "    ‚ÑπÔ∏è These two are tricky. They both are string values, and they both have two classes that are very common. On a real project, a good data scientist will study what those codes means <a href=\"http://vro.agriculture.vic.gov.au/dpi/vro/vrosite.nsf/pages/landform_land_systems_rees/$FILE/TECH_56%20ch6.pdf\"> by refering to the government publication</a>. In an ideal world we would explore different strategies for imputation (we will see this later in the course). However here we need to decide based on little evidence. Because we have no information, and because there is not a clear majority in either soil or landform classes, the best is to impute 'SoilTypeNA' and 'LandFormLSNA' as as a new class.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "fd189b43",
      "metadata": {
        "id": "fd189b43"
      },
      "outputs": [],
      "source": [
        "# ADD YOUR CODE HERE -- You can create new markdown and code cells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "7f249971",
      "metadata": {
        "id": "7f249971"
      },
      "outputs": [],
      "source": [
        "# ADD YOUR CODE HERE -- You can create new markdown and code cells"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e24c0ca",
      "metadata": {
        "id": "4e24c0ca"
      },
      "source": [
        "## `CanopyCont`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8c8e859",
      "metadata": {
        "id": "b8c8e859"
      },
      "source": [
        "üõÇ Check for missing values in `CanopyCont` and deal with them appropriately."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "310202e4",
      "metadata": {
        "id": "310202e4"
      },
      "source": [
        "<details>\n",
        "    <summary>üí° Hint </summary>\n",
        "    <br>\n",
        "    ‚ÑπÔ∏è If you do a <code>value_counts()</code> on <code>CanopyCont</code> you will see that this consists of 4 numerical variables, and 5 categorical variables. It is clear that this column has two different encoding for the same concept: how continuous is the canopy? The easiest is to transform this into a numerical column by doing the following replacements: 'none'=0, 'sparse'=1, 'patchy'=2, 'continous' or 'c' = 3. You probably want to use a python dictionary and an <code>apply()</code> function to do that, and remember to cast your values to an <code>int</code> or a <code>float</code>!\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "b23a8523",
      "metadata": {
        "id": "b23a8523"
      },
      "outputs": [],
      "source": [
        "# ADD YOUR CODE HERE -- You can create new markdown and code cells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "c700d71f",
      "metadata": {
        "id": "c700d71f"
      },
      "outputs": [],
      "source": [
        "dic = {'none':0,\n",
        "      'sparse':1,\n",
        "      'patchy':2,\n",
        "      'continuous':3,\n",
        "      'c':3}\n",
        "\n",
        "# Use an apply lambda function to replace the value. Cast to int, and return default value as 'x'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "34e57506",
      "metadata": {
        "id": "34e57506"
      },
      "outputs": [],
      "source": [
        "# print(f'# Missing CanopyCont:{df.CanopyCont.isnull().sum()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "006f6fff",
      "metadata": {
        "id": "006f6fff"
      },
      "source": [
        "### All the imputing is done!\n",
        "You should have zero missing values now."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "953ecf72",
      "metadata": {
        "id": "953ecf72"
      },
      "source": [
        "# Scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "696077bd",
      "metadata": {
        "id": "696077bd"
      },
      "source": [
        "üëá Investigate the numerical features for outliers and distribution, and apply the solutions below accordingly:\n",
        "- Robust Scale\n",
        "- Standard Scale\n",
        "\n",
        "Replace the original columns by the transformed values."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43ec3fdd",
      "metadata": {
        "id": "43ec3fdd"
      },
      "source": [
        "## `WidthVarie` , & `Powerline`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "795623ec",
      "metadata": {
        "id": "795623ec"
      },
      "source": [
        "‚öñÔ∏è Scale `WidthVarie` and `Powerline` using the most appropriate scaler."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec98765c",
      "metadata": {
        "id": "ec98765c"
      },
      "source": [
        "<details>\n",
        "    <summary>üí° Hint </summary>\n",
        "    <br>\n",
        "    ‚ÑπÔ∏è <code>WidthVarie</code>, & <code>Powerline</code> are clearly binary variable ([0,1]). They should not be scaled, but rater can optionally be encoded using a <code>CategoricalEncoder</code>. Simply leave them as they are.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "f01a00fd",
      "metadata": {
        "id": "f01a00fd"
      },
      "outputs": [],
      "source": [
        "# ADD YOUR CODE HERE -- You can create new markdown and code cells"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a30afef",
      "metadata": {
        "id": "2a30afef"
      },
      "source": [
        "## All other numerical variables"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3454cdcf",
      "metadata": {
        "id": "3454cdcf"
      },
      "source": [
        "‚öñÔ∏è How would you scale all of the other variables? Save a list of the numerical column names (minus `WidthVarie` and `Powerline`, see above) in a variable called `numerical_columns`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0477415b",
      "metadata": {
        "id": "0477415b"
      },
      "source": [
        "<details>\n",
        "    <summary>üí° Hint </summary>\n",
        "    <br>\n",
        "    ‚ÑπÔ∏è All other variables are continous, but their distribution is non-gaussian. We can use a RobustScaler() here. The first task is to identify the columns with a dtype of either 'float64' or 'int64': you can do this programmatically to avoid having to type a long list of features!\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "476ec0f9",
      "metadata": {
        "id": "476ec0f9"
      },
      "outputs": [],
      "source": [
        "# ADD YOUR CODE HERE -- You can create new markdown and code cells\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check for float and int variables\n",
        "\n",
        "# vstack the two data types into one numpy array\n",
        "\n",
        "#Transform numerical_colums to a list to more easily remove the two features"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a966b72",
      "metadata": {
        "id": "6a966b72"
      },
      "source": [
        "# Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52b4fbdf",
      "metadata": {
        "id": "52b4fbdf"
      },
      "source": [
        "üëá Investigate the non-numerical features that require encoding, and apply 'One hot encoding'. To ensure that we do not end up with an explosion of feature, we will retain only categorical features with <15 unique values for encoding.\n",
        "\n",
        "So your task is the following:\n",
        "\n",
        "1. Identify programmatically all of the categorical features that have <15 unique categories and require 'One Hot encoding'\n",
        "2. In the dataframe, replace the original features by their encoded version(s). Make sure to drop the original features, as well as the features with >15 unique categories from `df`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "448f6314",
      "metadata": {
        "id": "448f6314"
      },
      "outputs": [],
      "source": [
        "# ADD YOUR CODE HERE -- You can create new markdown and code cells"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e96cd889",
      "metadata": {
        "id": "e96cd889"
      },
      "source": [
        "# Base Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "889f94d5",
      "metadata": {
        "id": "889f94d5"
      },
      "source": [
        "üëá Cross validate a Linear regression model. Save its score under variable name `base_model_score`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "6f9954ee",
      "metadata": {
        "id": "6f9954ee"
      },
      "outputs": [],
      "source": [
        "# ADD YOUR CODE HERE -- You can create new markdown and code cells"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
